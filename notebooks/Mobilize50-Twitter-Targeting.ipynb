{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting political preferences from Twitter metadata ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting political affiliation based on Twitter data is a challenging problem that has been tackled via two primary approaches:\n",
    "\n",
    "- __Parsing text__ of individuals' tweets\n",
    "- Analyzing __metadata__ (followers, followees, etc.)\n",
    "\n",
    "Pennacchiotti and Popescu established in their [2010 paper](http://www.aaai.org/ocs/index.php/ICWSM/ICWSM11/paper/viewFile/2886/3262) that the latter approach is far more effective. Specifically, using only friends (i.e., who individual users follow on Twitter) can generate ~85% accuracy in predicting political affiliation, whereas text parsing coupled with a relatively sophisticated DLDA model does approximately 10 points worse.\n",
    "\n",
    "Here, we use a small set of well-known politicians and celebrities to divide users along ideological lines. We then learn a random forest model to classify users based on their affiliation. The final model achieves an accuracy of __~80%__ in predicting political affiliation, which likely can be improved as we refine the comparison set of \"followees\" (high-profile politicians we use to decide on a user's affiliation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import tweepy\n",
    "import csv\n",
    "import re\n",
    "import operator \n",
    "from collections import Counter\n",
    "from tweepy import OAuthHandler\n",
    "import sys\n",
    "import time\n",
    "import urllib2\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Retrieve consumer secret\n",
    "import json\n",
    "with open('../config.json') as data_file:    \n",
    "    secret_data = json.load(data_file)\n",
    "    consumer_secret = str(secret_data[0]['consumer_secret'])\n",
    "\n",
    "# Tweepy OAuth \n",
    "consumer_key = \"BVfNGMa15W5bKm2iRZHqLmNTx\"\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "access_token = \"52306095-Rr9ONTH5ZKbAcKDFj8h8AvsBPuH0x2qiRPWg7oaI6\"\n",
    "access_token_secret = \"vtZm8fNE2VxxCVhQCkrUMPeKxggdbMZFPSPy2LXctHIGm\"\n",
    " \n",
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    " \n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we're going to find 1000 Democrats and Republicans by searching for users who tweeted __\"#ImWithHer\"__ and __\"#MAGA.\"__\n",
    "\n",
    "Note that this clearly does not generate gold-standard test labels, as it is on the verge of being circular. We are trying to learn whether each user tweeted these campaign slogans, but our independent variables include whether each user follows Trump/Clinton on Twitter, a _very_ closely related outcome.\n",
    "\n",
    "We would ideally like some sort of self-reporting tool to use as our test set (i.e., find users who self-identified as Democrats and Republicans), although, unfortunately, the popular tools for self-identification (e.g., www.wefollow.com) seem to have shut down. A potential next step here would be to use Amazon Mechanical Turk to hand-label ~1000 users to build a more robust test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Democrat 100\n",
      "Democrat 200\n",
      "Democrat 300\n",
      "Democrat 400\n",
      "Democrat 500\n",
      "Democrat 600\n",
      "Democrat 700\n",
      "Democrat 800\n",
      "Democrat 900\n",
      "Democrat 1000\n",
      "Republican 100\n",
      "Republican 200\n",
      "Republican 300\n",
      "Republican 400\n",
      "Republican 500\n",
      "Republican 600\n",
      "Republican 700\n",
      "Republican 800\n",
      "Republican 900\n",
      "Republican 1000\n"
     ]
    }
   ],
   "source": [
    "democrats_iterator = tweepy.Cursor(api.search_users,\n",
    "                           q=\"#ImWithHer\",\n",
    "                           count=1000,\n",
    "                           result_type=\"recent\",\n",
    "                           include_entities=True,\n",
    "                           lang=\"en\").items(1000)\n",
    "\n",
    "republicans_iterator = tweepy.Cursor(api.search_users,\n",
    "                           q=\"#MAGA\",\n",
    "                           count=1000,\n",
    "                           result_type=\"recent\",\n",
    "                           include_entities=True,\n",
    "                           lang=\"en\").items(1000)\n",
    "\n",
    "democrat_ids = []\n",
    "republican_ids = []\n",
    "democrat_names = []\n",
    "republican_names = []\n",
    "\n",
    "count = 0\n",
    "for d in democrats_iterator:\n",
    "    count += 1\n",
    "    if count % 100 == 0:\n",
    "        print \"Democrat {0}\".format(count)\n",
    "    democrat_ids.append(d.id)\n",
    "    democrat_names.append(d.screen_name)\n",
    "\n",
    "count = 0\n",
    "for r in republicans_iterator:\n",
    "    count += 1\n",
    "    if count % 100 == 0:\n",
    "        print \"Republican {0}\".format(count)\n",
    "    republican_ids.append(r.id)\n",
    "    republican_names.append(r.screen_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then set out a standard list of __'followees'__, or politicians and celebrities we believe should strongly divide individuals along ideological lines. We can use the Twitter API to determine, for each (follower, followee) pair, whether there is a relationship or not (binary indicator of 1 or 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "followees = ['HillaryClinton', \n",
    "             'realDonaldTrump', \n",
    "             'tedcruz', \n",
    "             'elizabethforma', \n",
    "             'SenSanders', \n",
    "             'mike_pence',\n",
    "             'seanhannity']\n",
    "id_dict = {}\n",
    "for followee in followees:\n",
    "    results = api.get_user(followee)\n",
    "    id_dict[results.id] = results.screen_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_ids = pd.Series(democrat_ids[:25] + republican_ids[:25])\n",
    "user_names = pd.Series(democrat_names[:25] + republican_names[:25])\n",
    "dems = np.ones(len(democrat_ids))[:25]\n",
    "is_democrat = pd.Series(np.append(dems, np.zeros(len(republican_ids))[:25]))[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving realDonaldTrump data\n",
      "Processing follower number 20\n",
      "Rate limit reached. Sleeping for: 853\n",
      "Processing follower number 40\n",
      "Retrieving SenSanders data\n",
      "Processing follower number 20\n",
      "Processing follower number 40\n",
      "Retrieving mike_pence data\n",
      "Processing follower number 20\n",
      "Processing follower number 40\n",
      "Retrieving HillaryClinton data\n",
      "Processing follower number 20\n",
      "Processing follower number 40\n",
      "Retrieving elizabethforma data\n",
      "Rate limit reached. Sleeping for: 863\n",
      "Processing follower number 20\n",
      "Processing follower number 40\n",
      "Retrieving seanhannity data\n",
      "Processing follower number 20\n",
      "Processing follower number 40\n",
      "Retrieving tedcruz data\n",
      "Processing follower number 20\n",
      "Processing follower number 40\n"
     ]
    }
   ],
   "source": [
    "# Create pandas dataframe and prepopulate with dummy values\n",
    "\n",
    "# TODO: Figure out why one Republican username is repeated\n",
    "\n",
    "# user_ids = pd.Series(democrat_ids + republican_ids)\n",
    "# user_names = pd.Series(democrat_names + republican_names)\n",
    "# dems = np.ones(len(democrat_ids))\n",
    "# is_democrat = pd.Series(np.append(dems, np.zeros(len(republican_ids))))\n",
    "\n",
    "df = pd.DataFrame({ 'user_id' : user_ids,\n",
    "                    'user_names' : user_names,\n",
    "                    'is_democrat' : is_democrat,\n",
    "                    followees[0] : None,\n",
    "                    followees[1] : None,\n",
    "                    followees[2] : None,\n",
    "                    followees[3] : None,\n",
    "                    followees[4] : None,\n",
    "                    followees[5] : None,\n",
    "                    followees[6] : None\n",
    "                  })\n",
    "\n",
    "# Populate (follower, followee) pairs in the dataframe. Since we hit the rate limit \n",
    "# after 180 calls, this code takes ~19 hours to run. Potentially should find a workaround?\n",
    "\n",
    "for followee_id in id_dict:\n",
    "    followee = id_dict[followee_id]\n",
    "    print(\"Retrieving {0} data\".format(followee))\n",
    "    count = 0\n",
    "    for user_id in user_ids:\n",
    "        try:\n",
    "            friendship = api.show_friendship(source_id=user_id, target_id=followee_id)\n",
    "        except RateLimitError:\n",
    "            print(\"Sleeping for 15 minutes...\")\n",
    "            time.sleep(60*15)\n",
    "        follows_politician = friendship[1].followed_by\n",
    "        df.loc[df.user_id == user_id, followee] = follows_politician\n",
    "        count += 1\n",
    "        if (count % 20 == 0):\n",
    "            print(\"Processing follower number {0}\".format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save data file\n",
    "df.to_csv(\"saved_twitter_user_data_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.8 on a test set size of 50\n",
      "Accuracy is 0.7 on a test set size of 50\n",
      "Accuracy is 0.86 on a test set size of 50\n",
      "Accuracy is 0.86 on a test set size of 50\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import sklearn.ensemble as ensemble\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics\n",
    "import copy\n",
    "\n",
    "forest = ensemble.RandomForestClassifier()\n",
    "# feature_followees = copy.copy(followees)\n",
    "followee_sets = [['mike_pence', 'seanhannity'], ['elizabethforma','SenSanders'], ['realDonaldTrump', 'HillaryClinton'], followees]\n",
    "\n",
    "for feature_followees in followee_sets:\n",
    "    X = df.loc[:,feature_followees].as_matrix()\n",
    "    y = df.loc[:, 'is_democrat']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0, random_state=8)\n",
    "\n",
    "    forest.fit(X_train, y_train)\n",
    "    predictions = forest.predict(X_train)\n",
    "    accuracy = metrics.accuracy_score(predictions, y_train)\n",
    "    print(\"Accuracy is {0} on a test set size of {1}\".format(accuracy, len(predictions)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
